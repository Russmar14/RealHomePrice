---
title: "Untitled"
output: html_document
date: "2022-11-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages("caTools")
install.packages('neuralnet')
install.packages('sigmoid')
```


```{r loading packages}

library(tidyverse)
library(dplyr)
library(ggplot2)
library(neuralnet)
library(sigmoid)
library(broom)
library(caTools)
```

## R Markdown


```{r} 
realtor_data <- read_csv("realtor-data.csv")
```

```{r selecting required columns}
realtor_data1 <- realtor_data %>%
  select(c('price','bed','bath','house_size'))

realtor_data1
```

```{r  removing rows with null values}

cleaned_realtordata <- na.omit(realtor_data1)

## manually filtering the ouliers
filtered_realtor_data  <- cleaned_realtordata |> filter(price < 1000000 && bed < 15 && bath < 9 && house_size < 10000 )


## removing the price outliers 
outliers=boxplot(filtered_realtor_data$price,plot=FALSE)$out
outliers_data=filtered_realtor_data[which(filtered_realtor_data$price %in% outliers),]
filtered_realtor_data1= filtered_realtor_data[-which(filtered_realtor_data$price %in% outliers),]

cleaned_realtordata <- filtered_realtor_data1
```

```{r Normalization and Splitting data}

normalize2 <- function(x, na.rm = TRUE) {
    return((x- min(x)) / max(x))
}

normalized_data2 = as.data.frame(lapply(cleaned_realtordata, normalize2))

#min <- apply(cleaned_realtordata, 2, -min/max)
#max <- apply(cleaned_realtordata, 2, max)
#Scaled_data <- as.data.frame(scale(cleaned_realtordata, center = min, scale = max - min))

set.seed(12)
sample <- sample.split(normalized_data2$price, SplitRatio = 0.8) ## Splitting train and test data, train data = 80% of data 
train_data <- subset(normalized_data2, sample == TRUE)
test_data <- subset(normalized_data2, sample == FALSE)
```




```{r Getting Linear model setup}
linear_model_fit <- lm(price~bed+bath+house_size, data =train_data )
#quick summary of our model
summary(linear_model_fit)
#using tidy() to create a tibble of coefficients to use for neural network weights later
#weights_table <- tidy(linear_model_fit)
#user_data = data.frame(bed, bath, acre_lot, house_size)
```


```{r User input}
{
    bed = as.numeric(readline("Enter bed : "));
    bath = as.numeric(readline("Enter bath : "));
    house_size = as.numeric(readline("Enter house_size: "));
}

user_data = data.frame(bed, bath, house_size)


#   Function to Normalize user input  using (- min/max)
normalize_input <- function(user_Data) {
  bed = (user_Data[1,1]-min(cleaned_realtordata$bed))/(max(cleaned_realtordata$bed))
  bath = (user_Data[1,2]-min(cleaned_realtordata$bath))/(max(cleaned_realtordata$bath))
  house_size = (user_Data[1,3]-min(cleaned_realtordata$house_size))/(max(cleaned_realtordata$house_size))
  nor_User_data <- data.frame(bed, bath, house_size)
  return(nor_User_data)
}

#Normalising the user data 
nor_User_data <- normalize_input(user_data)


```


```{r Using a function}

##Function that takes in dataframe of normalized user data and gives out the output
predict_func <- function(nor_User_data) {
  predict(linear_model_fit, nor_User_data)
}
```

```{r}
unscale_price <- function(price) {
  price*(max(cleaned_realtordata$price))+min(cleaned_realtordata$price)
}
```

```{r}
pricelm <- predict_func(nor_User_data)
pricelm

#unscaling linear model price prediction
unscaled_price <- unscale_price(pricelm)



```




```{r}
library(sigmoid)



nn <- neuralnet(price~bed+bath+house_size,data=train_data,hidden=1, threshold=0.00001,act.fct=relu, rep=1, linear.output=TRUE, stepmax=1e6)
            
```




```{r}
#plotting
plot(nn)
#predicting price
price2 <- predict(nn,nor_User_data)

d <- price2[1]  
d
#unscaling price
unscaled_price <- unscale_price(pricelm)
```

```{r}
usethis::use_testthat()
```


```{r}
library(devtools)
library(usethis)

devtools::check()
```

```{r}
saveRDS(linear_model_fit, file = "linear_model_fit.rds")
saveRDS(nn, file = "nn.rds")
```
